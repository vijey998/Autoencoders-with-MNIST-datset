{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Convolutional Autoencoder : MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras as k\n",
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "plt.imshow(X_train[5678],cmap='gray')\n",
    "Xme=X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]\n",
      "(60000, 28, 28, 1)\n",
      "(10000, 28, 28, 1)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "X_train = X_train.reshape(60000,28,28,1)\n",
    "X_test = X_test.reshape(10000,28,28,1)\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "#noisy=noisy.reshape(60000,28,28,1)\n",
    "print(y_train[0])\n",
    "print(X_train.shape)\n",
    "#print(noisy.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "X_train= X_train.astype('float32')\n",
    "X_train /= 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_21 (Conv2D)           (None, 28, 28, 32)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 14, 14, 16)        2064      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 7, 7, 16)          0         \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 7, 7, 16)          0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_11 (UpSampling (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 14, 14, 32)        2080      \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_12 (UpSampling (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 28, 28, 64)        8256      \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 28, 28, 1)         65        \n",
      "=================================================================\n",
      "Total params: 12,625\n",
      "Trainable params: 12,625\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Dropout, GlobalAveragePooling2D,Reshape\n",
    "from keras.layers import Flatten, Dense,UpSampling2D\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "#Encoder\n",
    "model.add(Convolution2D(32, (2, 2), input_shape=(28,28,1),activation='relu', padding=\"same\"))\n",
    "model.add(MaxPooling2D(2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Convolution2D(16, (2, 2),activation='relu', padding=\"same\"))\n",
    "model.add(MaxPooling2D(2))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "#model.add(Convolution2D(8, (2, 2),activation='relu', padding=\"same\"))\n",
    "#model.add(MaxPooling2D(2)\n",
    "#model.add(Dropout(0.2))\n",
    "\n",
    "#model.add(Convolution2D(16, (2, 2),activation='relu', padding=\"same\"))\n",
    "#model.add(MaxPooling2D(2))\n",
    "#model.add(Dropout(0.2))\n",
    "\n",
    "#Decoder\n",
    "\n",
    "#model.add(UpSampling2D(size=(7,7)))\n",
    "#model.add(Convolution2D(8, (2, 2),activation='relu', padding=\"same\"))\n",
    "#model.add(Dropout(0.1))\n",
    "\n",
    "model.add(UpSampling2D(size=(2,2)))\n",
    "model.add(Convolution2D(32,(2, 2),activation='relu', padding=\"same\"))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(UpSampling2D(size=(2,2)))\n",
    "model.add(Convolution2D(64, (2, 2),activation='relu', padding=\"same\"))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "#model.add(Convolution2D(8, (2, 2),activation='relu', padding=\"same\"))\n",
    "#model.add(Dropout(0.2))\n",
    "#model.add(Dense(16,activation=\"relu\"))\n",
    "model.add(Dense(1,activation=\"sigmoid\"))\n",
    "\n",
    "\n",
    "          \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD, RMSprop, Adagrad, Adadelta, Adam, Adamax, Nadam\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import tensorflow as tf\n",
    "X=np.reshape(X_train,[60000,28,28,1])\n",
    "model.compile(optimizer ='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/5\n",
      "48000/48000 [==============================] - 416s 9ms/step - loss: 0.2612 - acc: 0.7978 - val_loss: 0.1461 - val_acc: 0.8036\n",
      "Epoch 2/5\n",
      "48000/48000 [==============================] - 404s 8ms/step - loss: 0.1468 - acc: 0.8024 - val_loss: 0.1209 - val_acc: 0.8092\n",
      "Epoch 3/5\n",
      "48000/48000 [==============================] - 401s 8ms/step - loss: 0.1279 - acc: 0.8073 - val_loss: 0.1089 - val_acc: 0.8115\n",
      "Epoch 4/5\n",
      "48000/48000 [==============================] - 401s 8ms/step - loss: 0.1199 - acc: 0.8090 - val_loss: 0.1027 - val_acc: 0.8128\n",
      "Epoch 5/5\n",
      "48000/48000 [==============================] - 405s 8ms/step - loss: 0.1153 - acc: 0.8098 - val_loss: 0.0993 - val_acc: 0.8129\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_train,X_train, validation_split = 0.2, epochs = 5, batch_size=256, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/10\n",
      "48000/48000 [==============================] - 404s 8ms/step - loss: 0.1114 - acc: 0.8105 - val_loss: 0.0950 - val_acc: 0.8136\n",
      "Epoch 2/10\n",
      "48000/48000 [==============================] - 422s 9ms/step - loss: 0.1079 - acc: 0.8111 - val_loss: 0.0924 - val_acc: 0.8141\n",
      "Epoch 3/10\n",
      "48000/48000 [==============================] - 430s 9ms/step - loss: 0.1056 - acc: 0.8115 - val_loss: 0.0908 - val_acc: 0.8142\n",
      "Epoch 4/10\n",
      "48000/48000 [==============================] - 438s 9ms/step - loss: 0.1042 - acc: 0.8117 - val_loss: 0.0897 - val_acc: 0.8144\n",
      "Epoch 5/10\n",
      "48000/48000 [==============================] - 460s 10ms/step - loss: 0.1030 - acc: 0.8119 - val_loss: 0.0887 - val_acc: 0.8145\n",
      "Epoch 6/10\n",
      "48000/48000 [==============================] - 469s 10ms/step - loss: 0.1022 - acc: 0.8120 - val_loss: 0.0881 - val_acc: 0.8146\n",
      "Epoch 7/10\n",
      "48000/48000 [==============================] - 434s 9ms/step - loss: 0.1015 - acc: 0.8121 - val_loss: 0.0875 - val_acc: 0.8148\n",
      "Epoch 8/10\n",
      "48000/48000 [==============================] - 436s 9ms/step - loss: 0.1010 - acc: 0.8122 - val_loss: 0.0868 - val_acc: 0.8149\n",
      "Epoch 9/10\n",
      "48000/48000 [==============================] - 432s 9ms/step - loss: 0.1004 - acc: 0.8122 - val_loss: 0.0867 - val_acc: 0.8149\n",
      "Epoch 10/10\n",
      "48000/48000 [==============================] - 417s 9ms/step - loss: 0.1000 - acc: 0.8123 - val_loss: 0.0860 - val_acc: 0.8148\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_train,X_train, validation_split = 0.2, epochs = 10, batch_size=128, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/10\n",
      "48000/48000 [==============================] - 402s 8ms/step - loss: 0.0992 - acc: 0.8124 - val_loss: 0.0855 - val_acc: 0.8151\n",
      "Epoch 2/10\n",
      "48000/48000 [==============================] - 402s 8ms/step - loss: 0.0990 - acc: 0.8124 - val_loss: 0.0854 - val_acc: 0.8149\n",
      "Epoch 3/10\n",
      "48000/48000 [==============================] - 408s 8ms/step - loss: 0.0988 - acc: 0.8124 - val_loss: 0.0853 - val_acc: 0.8149\n",
      "Epoch 4/10\n",
      "48000/48000 [==============================] - 524s 11ms/step - loss: 0.0986 - acc: 0.8125 - val_loss: 0.0850 - val_acc: 0.8150\n",
      "Epoch 5/10\n",
      "48000/48000 [==============================] - 477s 10ms/step - loss: 0.0985 - acc: 0.8125 - val_loss: 0.0849 - val_acc: 0.8150\n",
      "Epoch 6/10\n",
      "48000/48000 [==============================] - 452s 9ms/step - loss: 0.0983 - acc: 0.8125 - val_loss: 0.0847 - val_acc: 0.8150\n",
      "Epoch 7/10\n",
      "48000/48000 [==============================] - 435s 9ms/step - loss: 0.0982 - acc: 0.8125 - val_loss: 0.0846 - val_acc: 0.8151\n",
      "Epoch 8/10\n",
      "48000/48000 [==============================] - 426s 9ms/step - loss: 0.0980 - acc: 0.8125 - val_loss: 0.0845 - val_acc: 0.8151\n",
      "Epoch 9/10\n",
      "48000/48000 [==============================] - 452s 9ms/step - loss: 0.0979 - acc: 0.8125 - val_loss: 0.0844 - val_acc: 0.8150\n",
      "Epoch 10/10\n",
      "48000/48000 [==============================] - 456s 9ms/step - loss: 0.0978 - acc: 0.8126 - val_loss: 0.0844 - val_acc: 0.8151\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_train,X_train, validation_split = 0.2, epochs =10, batch_size=256, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2138469deb8>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "index=232\n",
    "\n",
    "x1=np.reshape(X_test[index],[1,28,28,1])\n",
    "y1=model.predict(x1)\n",
    "y1=np.reshape(y1,[28,28])\n",
    "f = plt.figure()\n",
    "f.add_subplot(1,2, 1)\n",
    "plt.imshow(np.reshape(x1,[28,28]),cmap=\"gray\")\n",
    "f.add_subplot(1,2, 2)\n",
    "plt.imshow(y1,cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_simple_conv_ae1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import tensorflow\n",
    "from tensorflow.losses import sigmoid_cross_entropy\n",
    "model = load_model('model_cae.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
